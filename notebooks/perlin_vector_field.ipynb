{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b589a2",
   "metadata": {},
   "source": [
    "# Precomputed Perlin Noise Vector Field\n",
    "\n",
    "A circular path in noise space drives a time-dependent 2D field. The workflow now splits into a simulation phase that precomputes vector samples and a render phase that reuses the cached data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext manim.utils.ipython_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4025c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple, cast\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from manim import (\n",
    "    Scene,\n",
    "    ValueTracker,\n",
    "    Arrow,\n",
    "    VGroup,\n",
    "    RIGHT,\n",
    "    color_gradient,\n",
    "    ManimColor,\n",
    "    FadeIn,\n",
    "    FadeOut,\n",
    "    smooth,\n",
    "    BLUE_E,\n",
    "    BLUE_C,\n",
    "    GREEN_B,\n",
    "    YELLOW_C,\n",
    "    RED_C,\n",
    ")\n",
    "\n",
    "# Minimal Perlin sampler so the notebook has no extra runtime dependencies.\n",
    "def _fade(t: np.ndarray | float) -> np.ndarray | float:\n",
    "    return 6 * t**5 - 15 * t**4 + 10 * t**3\n",
    "\n",
    "\n",
    "def _lerp(a: np.ndarray | float, b: np.ndarray | float, t: np.ndarray | float) -> np.ndarray | float:\n",
    "    return a + t * (b - a)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerlinSampler:\n",
    "    seed: int = 1\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        perm = np.arange(256, dtype=int)\n",
    "        rng.shuffle(perm)\n",
    "        self.permutation = np.concatenate([perm, perm])\n",
    "\n",
    "    def _gradient(self, hash_value: np.ndarray) -> np.ndarray:\n",
    "        gradients = np.array(\n",
    "            [\n",
    "                [1, 1, 0],\n",
    "                [-1, 1, 0],\n",
    "                [1, -1, 0],\n",
    "                [-1, -1, 0],\n",
    "                [1, 0, 1],\n",
    "                [-1, 0, 1],\n",
    "                [1, 0, -1],\n",
    "                [-1, 0, -1],\n",
    "                [0, 1, 1],\n",
    "                [0, -1, 1],\n",
    "                [0, 1, -1],\n",
    "                [0, -1, -1],\n",
    "            ]\n",
    "        )\n",
    "        return gradients[hash_value % gradients.shape[0]]\n",
    "\n",
    "    def __call__(self, x: float, y: float, z: float) -> float:\n",
    "        x_arr = np.asarray(x, dtype=float)\n",
    "        y_arr = np.asarray(y, dtype=float)\n",
    "        z_arr = np.asarray(z, dtype=float)\n",
    "\n",
    "        xi = np.floor(x_arr).astype(int) & 255\n",
    "        yi = np.floor(y_arr).astype(int) & 255\n",
    "        zi = np.floor(z_arr).astype(int) & 255\n",
    "        xf, yf, zf = x_arr - np.floor(x_arr), y_arr - np.floor(y_arr), z_arr - np.floor(z_arr)\n",
    "        u, v, w = _fade(xf), _fade(yf), _fade(zf)\n",
    "\n",
    "        def gradient_at(dx: float, dy: float, dz: float, px: int, py: int, pz: int) -> float:\n",
    "            hash_value = self.permutation[self.permutation[self.permutation[xi + px] + yi + py] + zi + pz]\n",
    "            gradient = self._gradient(hash_value)\n",
    "            return float(gradient[..., 0] * dx + gradient[..., 1] * dy + gradient[..., 2] * dz)\n",
    "\n",
    "        n000 = gradient_at(float(xf), float(yf), float(zf), 0, 0, 0)\n",
    "        n100 = gradient_at(float(xf - 1), float(yf), float(zf), 1, 0, 0)\n",
    "        n010 = gradient_at(float(xf), float(yf - 1), float(zf), 0, 1, 0)\n",
    "        n110 = gradient_at(float(xf - 1), float(yf - 1), float(zf), 1, 1, 0)\n",
    "        n001 = gradient_at(float(xf), float(yf), float(zf - 1), 0, 0, 1)\n",
    "        n101 = gradient_at(float(xf - 1), float(yf), float(zf - 1), 1, 0, 1)\n",
    "        n011 = gradient_at(float(xf), float(yf - 1), float(zf - 1), 0, 1, 1)\n",
    "        n111 = gradient_at(float(xf - 1), float(yf - 1), float(zf - 1), 1, 1, 1)\n",
    "\n",
    "        x1 = _lerp(n000, n100, u)\n",
    "        x2 = _lerp(n010, n110, u)\n",
    "        x3 = _lerp(n001, n101, u)\n",
    "        x4 = _lerp(n011, n111, u)\n",
    "        y1 = _lerp(x1, x2, v)\n",
    "        y2 = _lerp(x3, x4, v)\n",
    "        return float(_lerp(y1, y2, w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Centralized simulation controls for quick iteration\n",
    "simulation_output = Path(\"notebooks/data/perlin_vector_field_cache.npz\")  # File storing precomputed frames\n",
    "\n",
    "# How long to simulate and how densely to sample time\n",
    "duration = 8.0  # Seconds of simulated time captured in the cache\n",
    "frame_rate = 30  # Samples per second written to disk\n",
    "\n",
    "# Grid layout for the anchored arrows\n",
    "grid_x_span = (-4.5, 4.5)  # Inclusive horizontal bounds in scene units\n",
    "grid_y_span = (-2.5, 2.5)  # Inclusive vertical bounds in scene units\n",
    "grid_x_count = 20  # Number of anchors along the x-axis\n",
    "grid_y_count = 14  # Number of anchors along the y-axis\n",
    "\n",
    "# Perlin noise parameters controlling the flow pattern\n",
    "noise_seed = 7  # Seed for the Perlin sampler (reproducible flow)\n",
    "noise_scale = 0.6  # Scales scene coordinates into noise space\n",
    "noise_radius = 0.8  # Radius of the circular path through noise space\n",
    "noise_speed = 0.9  # Angular speed of the moving noise center (radians/sec)\n",
    "\n",
    "# Arrow styling\n",
    "arrow_length = 0.6  # Fixed length applied after normalizing vectors\n",
    "\n",
    "# Color grading for magnitudes\n",
    "color_bias = 0.2  # Baseline offset before mapping magnitude to palette index\n",
    "color_gain = 0.8  # Gain applied to magnitudes before color lookup\n",
    "palette: list[ManimColor] = cast(\n",
    "    list[ManimColor],\n",
    "    color_gradient([BLUE_E, BLUE_C, GREEN_B, YELLOW_C, RED_C], 64),\n",
    ")  # Gradient used to color arrows by magnitude\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d8e802b",
   "metadata": {},
   "source": [
    "## Map grid points into noise space\n",
    "\n",
    "Each grid anchor is scaled into noise coordinates, offset by a moving center, and sampled to produce a normalized vector and magnitude-driven color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sampler = PerlinSampler(seed=noise_seed)\n",
    "\n",
    "def sample_vector_field(point: np.ndarray, time: float) -> Tuple[np.ndarray, float]:\n",
    "    px, py = point[:2]\n",
    "    noise_center = np.array([math.cos(time * noise_speed), math.sin(time * noise_speed), 0.0]) * noise_radius\n",
    "    domain = np.array([px, py, time * 0.35]) * noise_scale + noise_center\n",
    "    dx = noise_sampler(*(domain + np.array([0.0, 0.0, 0.5])))\n",
    "    dy = noise_sampler(*(domain + np.array([2.3, -1.7, -0.25])))\n",
    "    vector = np.array([dx, dy])\n",
    "    magnitude = float(np.linalg.norm(vector))\n",
    "    if magnitude > 1e-6:\n",
    "        vector = vector / magnitude\n",
    "    vector *= arrow_length\n",
    "    return vector, magnitude\n",
    "\n",
    "\n",
    "def color_from_magnitude(magnitude: float) -> ManimColor:\n",
    "    scaled = float(np.clip(magnitude * color_gain + color_bias, 0, 1))\n",
    "    index = int(scaled * (len(palette) - 1))\n",
    "    return palette[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e4860a",
   "metadata": {},
   "source": [
    "## Stage 1: simulate and cache the field\n",
    "\n",
    "Sample the Perlin field on a fixed time grid, compute vectors for each anchor, and save the resulting positions and colors to disk. Re-run this cell whenever noise parameters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(output_path: Path = simulation_output) -> Path:\n",
    "    times = np.linspace(0.0, duration, int(duration * frame_rate) + 1)\n",
    "    xs = np.linspace(*grid_x_span, grid_x_count)\n",
    "    ys = np.linspace(*grid_y_span, grid_y_count)\n",
    "    anchors = np.array([[x, y, 0.0] for x in xs for y in ys], dtype=np.float32)\n",
    "\n",
    "    starts = np.repeat(anchors[None, ...], len(times), axis=0)\n",
    "    ends = np.zeros_like(starts)\n",
    "    magnitudes = np.zeros((len(times), len(anchors)), dtype=np.float32)\n",
    "    colors = np.empty((len(times), len(anchors)), dtype=\"<U7\")\n",
    "\n",
    "    for frame_index, t in enumerate(tqdm(times, desc=\"Simulating frames\")):\n",
    "        for anchor_index, anchor in enumerate(anchors):\n",
    "            vector, magnitude = sample_vector_field(anchor, float(t))\n",
    "            ends[frame_index, anchor_index] = anchor + np.append(vector, 0.0)\n",
    "            magnitudes[frame_index, anchor_index] = magnitude\n",
    "            colors[frame_index, anchor_index] = color_from_magnitude(magnitude).to_hex()\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(\n",
    "        output_path,\n",
    "        times=times.astype(np.float32),\n",
    "        anchors=anchors,\n",
    "        starts=starts,\n",
    "        ends=ends,\n",
    "        magnitudes=magnitudes,\n",
    "        colors=colors,\n",
    "        frame_dt=np.float32(times[1] - times[0] if len(times) > 1 else 0.0),\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "# Uncomment to regenerate the cache when parameters change.\n",
    "# simulation_path = run_simulation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd980d",
   "metadata": {},
   "source": [
    "## Stage 2: render from the cached data\n",
    "\n",
    "The Manim scene now reads the precomputed arrow positions and colors. The only animation logic during rendering is frame indexing, so Manim never re-samples the noise while drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerlinNoiseVectorField(Scene):\n",
    "    def construct(self) -> None:\n",
    "        if not simulation_output.exists():\n",
    "            raise FileNotFoundError(f\"Run the simulation stage to generate {simulation_output} before rendering.\")\n",
    "\n",
    "        cache = np.load(simulation_output)\n",
    "        anchors = cache[\"anchors\"]\n",
    "        starts = cache[\"starts\"]\n",
    "        ends = cache[\"ends\"]\n",
    "        colors = cache[\"colors\"]\n",
    "        frame_dt = float(cache[\"frame_dt\"])\n",
    "        total_frames = starts.shape[0]\n",
    "\n",
    "        def make_arrow(anchor: np.ndarray) -> Arrow:\n",
    "            return Arrow(\n",
    "                anchor,\n",
    "                anchor + RIGHT * 0.01,\n",
    "                buff=0,\n",
    "                max_stroke_width_to_length_ratio=2.5,\n",
    "                max_tip_length_to_length_ratio=0.35,\n",
    "                stroke_width=3.0,\n",
    "            )\n",
    "\n",
    "        frame_tracker = ValueTracker(0)\n",
    "\n",
    "        def update_arrow(arrow: Arrow, anchor_index: int) -> None:\n",
    "            frame_index = min(int(round(frame_tracker.get_value())), total_frames - 1)\n",
    "            arrow.put_start_and_end_on(starts[frame_index, anchor_index], ends[frame_index, anchor_index])\n",
    "            arrow.set_color(ManimColor(colors[frame_index, anchor_index]))\n",
    "\n",
    "        arrow_list: list[Arrow] = [make_arrow(anchor) for anchor in anchors]\n",
    "        arrows = VGroup(*arrow_list)\n",
    "\n",
    "        for index, arrow in enumerate(arrow_list):\n",
    "            arrow.add_updater(lambda mob, dt, idx=index: update_arrow(cast(Arrow, mob), idx))\n",
    "\n",
    "        self.play(FadeIn(arrows), run_time=1.5, rate_func=smooth)\n",
    "\n",
    "        def advance_frame(mob: ValueTracker, dt: float) -> None:\n",
    "            mob.increment_value(dt / frame_dt)\n",
    "\n",
    "        frame_tracker.add_updater(advance_frame)\n",
    "        self.wait(frame_dt * (total_frames - 1))\n",
    "\n",
    "        for arrow in arrow_list:\n",
    "            arrow.clear_updaters()\n",
    "        frame_tracker.clear_updaters()\n",
    "\n",
    "        self.play(FadeOut(arrows), run_time=1.0, rate_func=smooth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a314762",
   "metadata": {},
   "source": [
    "## Render the scene\n",
    "\n",
    "Use the Manim IPython magic to generate and display the animation inline. Adjust quality flags as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -qm -v WARNING PerlinNoiseVectorField"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
